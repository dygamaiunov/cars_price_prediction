import streamlit as st
import os
import pickle
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
from sklearn.compose import ColumnTransformer, TransformedTargetRegressor
from sklearn.impute import SimpleImputer
from sklearn.linear_model import Ridge
from sklearn.metrics import r2_score
import category_encoders as ce
import seaborn as sns
import matplotlib.pyplot as plt



def torque_power_extraction(df):
    # —Ä–µ–≥—É–ª—è—Ä–∫–∏ –Ω–∞–ø–∏—Å–∞–Ω—ã —Å –ø–æ–º–æ—â—å—é ChatGPT
    # –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ torque (–∫—Ä—É—Ç—è—â–∏–π –º–æ–º–µ–Ω—Ç) –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º, —Ç.–∫. –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏ –≤ –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–µ (Nm) –∏ –≤ –∞–∑–∏–∞—Ç—Å–∫–æ–º (kgm). –ü—Ä–∏–≤–æ–¥–∏–º –∫ –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–º—É —É–º–Ω–æ–∂–µ–Ω–∏–µ–º –Ω–∞ 9.8

    # —Ä–µ–≥—É–ª—è—Ä–∫–∞ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ kgm
    df['asian_torque'] = df['torque'].str.extract(r'(?i)(?=.*\bkgm?\b)\b(150(?:\.0+)?|[0-9]?[0-9](?:\.\d+)?|1[0-4][0-9](?:\.\d+)?)\b', expand = False).astype(float)*9.8

    # —Ä–µ–≥—É–ª—è—Ä–∫–∞ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ Nm
    df['european_torque'] = df['torque'].str.extract(r'(?i)(\d+(?:\.\d+)?)\s*Nm(?:\s*@|\s+at)\s*', expand = False).astype(float)
    df['torque_normalized'] = df['european_torque'].fillna(df['asian_torque'])

    # –∏–∑–≤–ª–µ–∫–∞–µ–º rpm (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–æ—Ä–æ—Ç–æ–≤ –≤ –º–∏–Ω—É—Ç—É, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è —É–∫–∞–∑–∞–Ω–Ω—ã–π torque)
    # –≤–∞–∂–Ω–æ, —á—Ç–æ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ rpm –≤–º–µ—Å—Ç–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞, —Ç–æ –æ–Ω–æ —É–π–¥—ë—Ç –≤ max_rpm
    df['rpm'] = df['torque'].str.extract(r'(\d{1,4}(?:[.,]\d{1,3})?(?:\s*[-‚Äì]\s*\d{1,4}(?:[.,]\d{1,3})?)?)(?=[^\d]*rpm)')
    out = df['rpm'].str.replace(',', '').str.extract(r'(?P<min>\d[\d,]*)(?:-(?P<max>\d[\d,]*))?').replace(',', '')

    out['max'] = out['max'].fillna(out['min'])
    df['max_rpm'] = out['max']
    df['max_rpm'] = pd.to_numeric(df['max_rpm'], errors='coerce')

    # —Ñ–∏–Ω–∞–ª—å–Ω–æ —Å—á–∏—Ç–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é  –º–æ—â–Ω–æ—Å—Ç—å –¥–≤–∏–≥–∞—Ç–µ–ª—è –ø–æ —Ñ–æ—Ä–º—É–ª–µ P (–í—Ç) = Torque * RPM * 0.10472
    df['torque_power'] = df['torque_normalized'] * df['max_rpm'] * 0.10472

    df.drop(['european_torque', 'asian_torque', 'torque', 'rpm', 'torque_normalized', 'max_rpm'], axis = 1, inplace = True)

    return df


def columns_preprocessing(df):
    df['mileage'] = df['mileage'].str.extract(r'(?i)(\d+(?:\.\d+)?)\s*kmpl', expand=False).astype(float)
    df['engine'] = df['engine'].str.extract(r'(?i)(\d+(?:\.\d+)?)\s*CC', expand=False).astype(float)
    df['max_power'] = df['max_power'].str.extract(r'(?i)(\d+(?:\.\d+)?)\s*bhp', expand=False).astype(float)

    return df


def name_preprocessing(df):
    # —Ä–µ–≥—É–ª—è—Ä–∫–∏ –Ω–∞–ø–∏—Å–∞–Ω—ã —Å –ø–æ–º–æ—â—å—é ChatGPT
    # –¥–æ—Å—Ç–∞—ë–º bs_emission –∏–∑ –ª—é–±–æ–π –ø–æ–∑–∏—Ü–∏–∏ —Å—Ç—Ä–æ–∫–∏
    bs_pattern = r'(BS[ -]?(?:VI|IV|V|I{1,3}|[1-6]))'
    df['bs_emission'] = df['name'].str.extract(bs_pattern, expand=False).str.replace(' ', '').fillna('not stated')

    # —É–±–∏—Ä–∞–µ–º bs_emission –∏–∑ name, —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞–ª—Å—è –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ
    name_clean = (
        df['name']
        .str.replace(bs_pattern, '', regex=True)   # –≤—ã—Ä–µ–∑–∞–µ–º "BS IV" –∏ —Ç.–ø.
        .str.replace(r'\s+', ' ', regex=True)      # —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        .str.strip()
    )

    # —Ä–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è brand, model (–º–æ–¥–µ–ª—å –º–∞—à–∏–Ω—ã), variant (–≤–∞—Ä–∏–∞–Ω—Ç –º–æ–¥–µ–ª–∏)
    pattern = r'''^(?P<brand>[A-Za-z]+)\s+(?P<model>[A-Za-z0-9]+(?:\s+[A-Za-z0-9]{1,2})?)(?:\s+(?P<variant>.*))?$'''

    # –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ –æ—á–∏—â–µ–Ω–Ω–æ–º—É name –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ df
    cols = name_clean.str.extract(pattern)
    df = pd.concat([df, cols], axis=1)
    df.drop(columns = ['name'], inplace = True)

    return df


def type_casting(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df['engine'] = pd.to_numeric(df['engine'], errors='coerce').astype('Int64')
    df['seats']  = pd.to_numeric(df['seats'], errors='coerce').astype('Int64')
    return df



@st.cache_resource  # –ö—ç—à–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å (–∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑)
def load_model():
    with open('improved_ridge_regression_pipeline.pkl', 'rb') as f:
        model = pickle.load(f)
    return model

model = load_model()

@st.cache_data
def load_train():
    # —á–∏—Ç–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
    df_train = pd.read_csv('https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_train.csv')
    df_test = pd.read_csv('https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_test.csv')
    return df_train, df_test

df_train, df_test = load_train()

# --- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ ---
st.subheader("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")


num_cols = df_train.select_dtypes(include=[np.number]).columns

# pairplot
pp = sns.pairplot(df_train[num_cols], y_vars=["selling_price"])
pp.fig.suptitle("–í–∑–∞–∏–º–æ—Å–≤—è–∑—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ü–µ–Ω–æ–π", y=1.02)
st.pyplot(pp.fig)

# correlation
pearson_corr = df_train[num_cols].corr()

fig, ax = plt.subplots(figsize=(8, 6))
sns.heatmap(pearson_corr, annot=True, fmt=".2f", ax=ax)

# –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤–Ω—É—Ç—Ä–∏ —Ñ–∏–≥—É—Ä—ã
ax.set_title("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", pad=16)

st.pyplot(fig)

# —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–æ–≥ —Ç–∞—Ä–≥–µ—Ç–∞
TARGET_COL = "selling_price"

y_train = df_train[TARGET_COL]
y_train_ln = np.log(y_train)  # –∏–ª–∏ np.log1p, –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –µ—Å—Ç—å –Ω—É–ª–∏

fig, ax = plt.subplots(figsize=(8, 5))
ax.hist(y_train_ln, bins=50)
ax.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ ln(selling_price)")
ax.set_xlabel("ln(selling_price)")
ax.set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞")

st.pyplot(fig)


# --- –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
st.title("üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –º–∞—à–∏–Ω—ã")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    test_sample = df.drop(columns=[TARGET_COL])
    y_test_ = df[TARGET_COL]

    prediction = model.predict(test_sample)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    st.metric("R-–∫–≤–∞–¥—Ä–∞—Ç", r2_score(y_test_, prediction))
  

    # --- –í–µ—Å–∞ –º–æ–¥–µ–ª–∏---
    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")

    tabular = model.named_steps["tabular"]
        feature_names = tabular.get_feature_names_out()

        
        final_reg = model.named_steps["reg"]
        coefs = final_reg.regressor_.coef_

        # c–æ–±–∏—Ä–∞–µ–º —Ç–∞–±–ª–∏—á–∫—É
        coefs_df = pd.DataFrame({
            '–ü—Ä–∏–∑–Ω–∞–∫': feature_names,
            '–í–µ—Å': np.abs(coefs)
        }).sort_values('–í–µ—Å', ascending=False)

    st.subheader("–í–µ—Å–∞ –º–æ–¥–µ–ª–∏:")
    st.dataframe(coefs_df.head(20), use_container_width=True)
